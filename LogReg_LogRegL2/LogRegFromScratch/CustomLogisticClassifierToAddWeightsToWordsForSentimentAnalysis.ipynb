{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom logistic classifier to add weights to words for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate as tc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = tc.SFrame(\"amazon_baby_subset.sframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('important_words.json', 'r') as f: # Reads the list of most frequent words\n",
    "    important_words = json.load(f)\n",
    "important_words = [str(s) for s in important_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "def remove_punctuation(text):\n",
    "    translator = text.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    return text\n",
    "\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['contains_perfect'] = products['perfect'].apply(lambda n : n != 0)\n",
    "products['contains_perfect'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, label):\n",
    "    data_sframe['intercept'] = 1\n",
    "    features = ['intercept'] + features\n",
    "    features_sframe = data_sframe[features]\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    label_sarray = data_sframe[label]\n",
    "    label_array = label_sarray.to_numpy()\n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, sentiment = get_numpy_data(products, important_words, 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53072, 194)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "estimate ranges between 0 and 1.\n",
    "'''\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    # Take dot product of feature_matrix and coefficients  \n",
    "    dot = np.dot(feature_matrix,coefficients)\n",
    "    \n",
    "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
    "    \n",
    "    predictions = 1/(1 + np.exp(-dot))\n",
    "    \n",
    "    # return predictions\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):     \n",
    "    # Compute the dot product of errors and feature\n",
    "    derivative = np.dot(errors,feature)\n",
    "    \n",
    "    # Return the derivative\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    logexp = np.log(1. + np.exp(-scores))\n",
    "    \n",
    "    # Simple check to prevent overflow\n",
    "    mask = np.isinf(logexp)\n",
    "    logexp[mask] = -scores[mask]\n",
    "    \n",
    "    lp = np.sum((indicator-1)*scores - logexp)\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    for itr in range(max_iter):\n",
    "\n",
    "        # Predict P(y_i = +1|x_i,w) using your predict_probability() function\n",
    "        \n",
    "        predictions = predict_probability(feature_matrix,coefficients)\n",
    "        \n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "        \n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "        \n",
    "        for j in range(len(coefficients)): # loop over each coefficient\n",
    "            \n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j].\n",
    "            # Compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            \n",
    "            derivative = feature_derivative(errors,feature_matrix[:,j])\n",
    "            \n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            coefficients[j] += step_size*derivative\n",
    "        \n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
    "            print('iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp))\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -36780.91768478\n",
      "iteration   1: log likelihood of observed labels = -36775.13434712\n",
      "iteration   2: log likelihood of observed labels = -36769.35713564\n",
      "iteration   3: log likelihood of observed labels = -36763.58603240\n",
      "iteration   4: log likelihood of observed labels = -36757.82101962\n",
      "iteration   5: log likelihood of observed labels = -36752.06207964\n",
      "iteration   6: log likelihood of observed labels = -36746.30919497\n",
      "iteration   7: log likelihood of observed labels = -36740.56234821\n",
      "iteration   8: log likelihood of observed labels = -36734.82152213\n",
      "iteration   9: log likelihood of observed labels = -36729.08669961\n",
      "iteration  10: log likelihood of observed labels = -36723.35786366\n",
      "iteration  11: log likelihood of observed labels = -36717.63499744\n",
      "iteration  12: log likelihood of observed labels = -36711.91808422\n",
      "iteration  13: log likelihood of observed labels = -36706.20710739\n",
      "iteration  14: log likelihood of observed labels = -36700.50205049\n",
      "iteration  15: log likelihood of observed labels = -36694.80289716\n",
      "iteration  20: log likelihood of observed labels = -36666.39512033\n",
      "iteration  30: log likelihood of observed labels = -36610.01327118\n",
      "iteration  40: log likelihood of observed labels = -36554.19728365\n",
      "iteration  50: log likelihood of observed labels = -36498.93316099\n",
      "iteration  60: log likelihood of observed labels = -36444.20783914\n",
      "iteration  70: log likelihood of observed labels = -36390.00909449\n",
      "iteration  80: log likelihood of observed labels = -36336.32546144\n",
      "iteration  90: log likelihood of observed labels = -36283.14615871\n",
      "iteration 100: log likelihood of observed labels = -36230.46102347\n",
      "iteration 200: log likelihood of observed labels = -35728.89418769\n",
      "iteration 300: log likelihood of observed labels = -35268.51212683\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression(feature_matrix, sentiment, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=1e-7, max_iter=301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25126 27946\n"
     ]
    }
   ],
   "source": [
    "scores = np.dot(feature_matrix, coefficients)\n",
    "p,n=0,0\n",
    "for i in scores:\n",
    "    if i>0:\n",
    "        p+=1\n",
    "    else:\n",
    "        n+=1\n",
    "print(p,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4734323183599638"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_mistakes = len(products['sentiment']) - p\n",
    "accuracy  = (len(products) - num_mistakes)/len(products)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = list(coefficients[1:]) # exclude intercept\n",
    "word_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficients)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('use', -0.05386014844520313),\n",
       " ('bought', -0.0415110333921089),\n",
       " ('day', -0.03898203728648711),\n",
       " ('bottles', -0.03306951529475273),\n",
       " ('first', -0.030051249236035808),\n",
       " ('however', -0.028978976142317068),\n",
       " ('well', -0.028711552980192588),\n",
       " ('still', -0.02774269723066133),\n",
       " ('waste', -0.026592778462247283),\n",
       " ('money', -0.02448210054589172),\n",
       " ('cup', -0.02404274807115496),\n",
       " ('tried', -0.02139434854368248),\n",
       " ('go', -0.019846256660777207),\n",
       " ('monitor', -0.01870237142432583),\n",
       " ('clean', -0.018359460662945686),\n",
       " ('son', -0.018246193486087036),\n",
       " ('since', -0.017737543997218053),\n",
       " ('never', -0.017137867010854794),\n",
       " ('come', -0.016001798500102516),\n",
       " ('took', -0.015537698955653887),\n",
       " ('thing', -0.015040658977043393),\n",
       " ('hard', -0.014977044903587944),\n",
       " ('disappointed', -0.01486631944997698),\n",
       " ('actually', -0.014709833465080667),\n",
       " ('quality', -0.013868727265297587),\n",
       " ('item', -0.0137566767312614),\n",
       " ('recommend', -0.013213475301677043),\n",
       " ('thought', -0.012969046546319293),\n",
       " ('reviews', -0.012808838024750812),\n",
       " ('milk', -0.012754571329579798),\n",
       " ('try', -0.012605189953662308),\n",
       " ('last', -0.012506394670958822),\n",
       " ('time', -0.012170641997242548),\n",
       " ('instead', -0.012101030310887904),\n",
       " ('went', -0.011895059489782875),\n",
       " ('high', -0.011523047555497197),\n",
       " ('us', -0.01095091216964983),\n",
       " ('water', -0.010918793208793),\n",
       " ('something', -0.010770935491004767),\n",
       " ('piece', -0.010669132724912935),\n",
       " ('bag', -0.010576801537792876),\n",
       " ('second', -0.010282634317735408),\n",
       " ('trying', -0.010219204790778673),\n",
       " ('using', -0.01014765551165753),\n",
       " ('picture', -0.010006213059178754),\n",
       " ('pretty', -0.009874247980135876),\n",
       " ('cheap', -0.009315208191956718),\n",
       " ('bottle', -0.009259144043189976),\n",
       " ('gate', -0.009120491910748275),\n",
       " ('makes', -0.009066533373590218),\n",
       " ('came', -0.008935728615993482),\n",
       " ('baby', -0.008502046745757363),\n",
       " ('bottom', -0.008317829807696091),\n",
       " ('seems', -0.008101502952676016),\n",
       " ('sure', -0.007764187808314247),\n",
       " ('many', -0.007732287817370993),\n",
       " ('looking', -0.007372630597764411),\n",
       " ('works', -0.007353459369094527),\n",
       " ('started', -0.007224199425910096),\n",
       " ('open', -0.007220988012088567),\n",
       " ('almost', -0.00709205934413514),\n",
       " ('getting', -0.007075730981647346),\n",
       " ('bad', -0.007041719908427806),\n",
       " ('different', -0.0070079191164656805),\n",
       " ('going', -0.006952869149061941),\n",
       " ('way', -0.006910108112146037),\n",
       " ('less', -0.006870502394402383),\n",
       " ('head', -0.006762897175112026),\n",
       " ('won', -0.006475876873018086),\n",
       " ('purchased', -0.006413688585050478),\n",
       " ('want', -0.006409589155003783),\n",
       " ('returned', -0.0064009893446270215),\n",
       " ('know', -0.006300542962225543),\n",
       " ('stay', -0.006300126718179463),\n",
       " ('give', -0.006262831503162304),\n",
       " ('made', -0.006087140302347556),\n",
       " ('said', -0.005654987222257695),\n",
       " ('away', -0.0056057334752514145),\n",
       " ('anything', -0.005470161541392434),\n",
       " ('wish', -0.005443003464382597),\n",
       " ('set', -0.0052878621959721525),\n",
       " ('big', -0.0052058842106071585),\n",
       " ('plastic', -0.00510287978487711),\n",
       " ('ordered', -0.00510115608429506),\n",
       " ('amazon', -0.0050412750790588155),\n",
       " ('pump', -0.00504082163624915),\n",
       " ('hold', -0.005012917306197127),\n",
       " ('got', -0.00479579527809302),\n",
       " ('work', -0.004789909428673402),\n",
       " ('fits', -0.004659737406888564),\n",
       " ('daughter', -0.004397000674509431),\n",
       " ('maybe', -0.004266443864014709),\n",
       " ('problem', -0.004074970100351703),\n",
       " ('say', -0.003814164093684311),\n",
       " ('weeks', -0.00373694385874852),\n",
       " ('though', -0.003509845157568247),\n",
       " ('would', -0.0035048841333352094),\n",
       " ('top', -0.0034808852314084314),\n",
       " ('difficult', -0.003413309289188653),\n",
       " ('look', -0.0033188773175082003),\n",
       " ('size', -0.00305345475933087),\n",
       " ('idea', -0.0030257887493927997),\n",
       " ('looks', -0.003018666010667182),\n",
       " ('company', -0.002478056986088657),\n",
       " ('worked', -0.0022203440239695676),\n",
       " ('enough', -0.00220317660562307),\n",
       " ('return', -0.001973209371896164),\n",
       " ('chair', -0.0019419955109540182),\n",
       " ('received', -0.0016689531424132914),\n",
       " ('wanted', -0.001645751447384549),\n",
       " ('put', -0.0013621951573487413),\n",
       " ('find', -0.0012476158571719635),\n",
       " ('tub', -0.0011449351626316184),\n",
       " ('part', -0.0009762196756223372),\n",
       " ('lot', -0.0008613904437686891),\n",
       " ('two', -0.000657350362092344),\n",
       " ('times', -0.0005159604846262287),\n",
       " ('best', -0.00033566600034981673),\n",
       " ('play', -0.00018857228050011144),\n",
       " ('working', -0.0001864892356677632),\n",
       " ('purchase', 1.366992855023106e-05),\n",
       " ('price', 9.916668274814236e-05),\n",
       " ('babies', 0.0001198850034678087),\n",
       " ('also', 0.0002725920624677587),\n",
       " ('worth', 0.0004120917130065566),\n",
       " ('back', 0.0006101288089752654),\n",
       " ('found', 0.0008292511599959563),\n",
       " ('stroller', 0.0008992390814154661),\n",
       " ('place', 0.0012225783235106365),\n",
       " ('see', 0.0015136828514065379),\n",
       " ('design', 0.0015347116392846493),\n",
       " ('soft', 0.0015547861236921195),\n",
       " ('comfortable', 0.001723070510231438),\n",
       " ('easily', 0.0017456314732199947),\n",
       " ('night', 0.002187240162161944),\n",
       " ('box', 0.0022363904560238454),\n",
       " ('broke', 0.0023134923740490212),\n",
       " ('cover', 0.0026466106385121296),\n",
       " ('product', 0.0027682039063976803),\n",
       " ('bit', 0.002808259066683149),\n",
       " ('unit', 0.0028153321886465335),\n",
       " ('buying', 0.0028581898513427404),\n",
       " ('nice', 0.002861787516105207),\n",
       " ('toy', 0.0029803067506612617),\n",
       " ('diaper', 0.003067855012990108),\n",
       " ('new', 0.003081478639854044),\n",
       " ('together', 0.0033448995950862933),\n",
       " ('little', 0.003983533639413617),\n",
       " ('completely', 0.004020376508099751),\n",
       " ('around', 0.004279382890354769),\n",
       " ('year', 0.004606618761970606),\n",
       " ('love', 0.0050174388165654124),\n",
       " ('every', 0.00553751236405903),\n",
       " ('without', 0.005674789908056568),\n",
       " ('need', 0.00573320002848789),\n",
       " ('better', 0.005923536113220274),\n",
       " ('think', 0.006002799788638705),\n",
       " ('child', 0.006437668081870188),\n",
       " ('make', 0.006710123314664173),\n",
       " ('small', 0.007171907270027091),\n",
       " ('fit', 0.007508918097314341),\n",
       " ('right', 0.007999389349248329),\n",
       " ('car', 0.008264666945374461),\n",
       " ('able', 0.00858284300434653),\n",
       " ('take', 0.009032818138954405),\n",
       " ('another', 0.009178428983984311),\n",
       " ('month', 0.009572733543590178),\n",
       " ('buy', 0.009783241021568065),\n",
       " ('loves', 0.009909164635972734),\n",
       " ('keep', 0.0107159665162703),\n",
       " ('room', 0.011703160621987424),\n",
       " ('kids', 0.01170824809312326),\n",
       " ('really', 0.011944817713693951),\n",
       " ('crib', 0.012018174433365525),\n",
       " ('months', 0.012685935745813373),\n",
       " ('happy', 0.0132539900815849),\n",
       " ('cute', 0.014991791565630266),\n",
       " ('get', 0.015216196422918844),\n",
       " ('used', 0.015408450108008665),\n",
       " ('side', 0.016805295889768077),\n",
       " ('long', 0.016882471071408715),\n",
       " ('could', 0.017570272245602887),\n",
       " ('good', 0.01770319990570169),\n",
       " ('perfect', 0.018408707995268996),\n",
       " ('seat', 0.020077541034775378),\n",
       " ('even', 0.02973993710496846),\n",
       " ('old', 0.03013500109210707),\n",
       " ('much', 0.04497640139490604),\n",
       " ('easy', 0.04543562630842137),\n",
       " ('like', 0.06479458680257838),\n",
       " ('great', 0.06589076292212326),\n",
       " ('one', 0.06654608417045771)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
